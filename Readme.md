# ğŸ“š RAG AI Knowledge Assistant (Streamlit)


---

## âœ¨ Key Features

- ğŸ“„ Upload **any PDF** at runtime
- ğŸ§¹ Text cleaning + smart sentenceâ€‘aware chunking
- ğŸ” Semantic search using **Sentence Transformers + FAISS**
- ğŸ¯ Query rewriting, filtering & crossâ€‘encoder reâ€‘ranking
- ğŸ¤– Answer generation using **Groq LLaMAâ€‘4**
- ğŸ–¥ï¸ Simple **Streamlit UI** for demos & interviews

---

## ğŸ§  Core Design Principle

> **Nothing runs by default.**  
> The RAG pipeline executes **only after a PDF is uploaded**.

This avoids accidental indexing, ghost data, and interview red flags.

---

## ğŸ“ Folder Structure

```
rag_project/practise/
â”‚
â”œâ”€â”€ app.py                 # Streamlit UI (entry point)
â”œâ”€â”€ ingest.py              # PDF ingestion logic (pure function)
â”œâ”€â”€ pdf_loader.py          # Load text from PDFs
â”œâ”€â”€ cleaner.py             # Text cleaning utilities
â”œâ”€â”€ chunker.py             # Smart sentence-based chunking
â”œâ”€â”€ vector_store.py        # FAISS vector database
â”œâ”€â”€ smart_retriever.py     # Query rewrite â†’ filter â†’ rerank
â”œâ”€â”€ reranker.py            # Cross-encoder re-ranking
â”œâ”€â”€ context_builder.py     # Context construction for LLM
â”œâ”€â”€ prompt.py              # System + user prompt template
â”œâ”€â”€ llm.py                 # Groq LLM wrapper
â”œâ”€â”€ rag_pipeline.py        # End-to-end RAG orchestration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploaded.pdf       # Uploaded PDF (runtime only)
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

| Component | Tool |
|---------|------|
| UI | Streamlit |
| Embeddings | `all-MiniLM-L6-v2` |
| Vector DB | FAISS |
| Reranker | `ms-marco-MiniLM` CrossEncoder |
| LLM | Groq â€“ LLaMAâ€‘4 Maverick |
| PDF Parsing | PyPDF |

---

## ğŸš€ How It Works (Flow)

1. **Upload PDF** via Streamlit
2. Text extracted pageâ€‘wise
3. Cleaned & sentenceâ€‘aware chunking
4. Embeddings generated & indexed in FAISS
5. User query â†’ rewritten â†’ retrieved â†’ reranked
6. Context built from top chunks
7. LLM answers **only from context**

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

Then:
1. Upload a PDF
2. Ask questions related **only to that document**

---

## ğŸ” Environment Setup

Set your Groq API key:

**Windows (PowerShell)**
```powershell
setx GROQ_API_KEY "your_api_key_here"
```

**Linux / macOS**
```bash
export GROQ_API_KEY="your_api_key_here"
```

---


## âœ… What This Project Demonstrates

- Realâ€‘world RAG architecture (not a tutorial clone)
- Strong separation of concerns
- LLM grounding & hallucination control
- Practical Streamlit deployment

---

## ğŸ“Œ Future Enhancements

- Persistent FAISS index
- Multiâ€‘PDF support
- Source citation highlighting
- Dockerization

---

## ğŸ‘¨â€ğŸ’» Author

Built with focus on **clarity, correctness**.


